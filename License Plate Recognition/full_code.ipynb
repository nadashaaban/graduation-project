{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7c6b5-cee3-436d-bad9-365edaf50ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "image_folder = 'D:/nada/grad_project/Car Plate Recognition - Final/datasets/plates/test/images'\n",
    "plate_model = YOLO('D:/nada/grad_project/Car Plate Recognition - Final/plates_best_so_far.pt')\n",
    "letter_model = YOLO('D:/nada/grad_project/Car Plate Recognition - Final/letters1.pt')\n",
    "\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(('.jpg', '.png')):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        ### STEP 1: Detect plates ###\n",
    "        plate_results = plate_model(img)\n",
    "        plate_boxes = plate_results[0].boxes.xyxy.tolist()\n",
    "        plate_confs = plate_results[0].boxes.conf.tolist()\n",
    "\n",
    "        for plate_box, plate_conf in zip(plate_boxes, plate_confs):\n",
    "            if plate_conf < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, plate_box)\n",
    "            cropped_plate = img[y1:y2, x1:x2]\n",
    "\n",
    "            ### STEP 2: Detect letters in the cropped plate ###\n",
    "            letter_results = letter_model(cropped_plate)\n",
    "            letter_boxes = letter_results[0].boxes.xyxy.tolist()\n",
    "            letter_classes = letter_results[0].boxes.cls.tolist()\n",
    "            letter_confs = letter_results[0].boxes.conf.tolist()\n",
    "            letter_names = letter_results[0].names\n",
    "\n",
    "            for box, cls, conf in zip(letter_boxes, letter_classes, letter_confs):\n",
    "                if conf < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                lx1, ly1, lx2, ly2 = map(int, box)\n",
    "                class_name = letter_names[int(cls)]\n",
    "\n",
    "                # Convert letter box back to original image coordinates\n",
    "                abs_x1 = lx1 + x1\n",
    "                abs_y1 = ly1 + y1\n",
    "                abs_x2 = lx2 + x1\n",
    "                abs_y2 = ly2 + y1\n",
    "\n",
    "                # Draw bounding box on original image (optional)\n",
    "                cv2.rectangle(img, (abs_x1, abs_y1), (abs_x2, abs_y2), (0, 255, 0), 2)\n",
    "                cv2.putText(img, class_name, (abs_x1, abs_y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "\n",
    "        ### Show result ###\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa294b75-2a41-413d-9c7e-ddbde0049207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define paths\n",
    "image_folder = 'D:/nada/grad_project/Car Plate Recognition - Final/datasets/plates/test/images'\n",
    "plate_model = YOLO('D:/nada/grad_project/Car Plate Recognition - Final/plates_best_so_far.pt')\n",
    "letter_model = YOLO('D:/nada/grad_project/Car Plate Recognition - Final/letters1.pt')\n",
    "\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(('.jpg', '.png')):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        ### STEP 1: Detect plates ###\n",
    "        plate_results = plate_model(img)\n",
    "        plate_boxes = plate_results[0].boxes.xyxy.tolist()\n",
    "        plate_confs = plate_results[0].boxes.conf.tolist()\n",
    "\n",
    "        for plate_box, plate_conf in zip(plate_boxes, plate_confs):\n",
    "            if plate_conf < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, plate_box)\n",
    "            cropped_plate = img[y1:y2, x1:x2]\n",
    "\n",
    "            ### STEP 2: Detect letters in the cropped plate ###\n",
    "            letter_results = letter_model(cropped_plate)\n",
    "            letter_boxes = letter_results[0].boxes.xyxy.tolist()\n",
    "            letter_classes = letter_results[0].boxes.cls.tolist()\n",
    "            letter_confs = letter_results[0].boxes.conf.tolist()\n",
    "            letter_names = letter_results[0].names\n",
    "\n",
    "            for box, cls, conf in zip(letter_boxes, letter_classes, letter_confs):\n",
    "                if conf < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                lx1, ly1, lx2, ly2 = map(int, box)\n",
    "                class_name = letter_names[int(cls)]\n",
    "\n",
    "                # Convert letter box back to original image coordinates\n",
    "                abs_x1 = lx1 + x1\n",
    "                abs_y1 = ly1 + y1\n",
    "                abs_x2 = lx2 + x1\n",
    "                abs_y2 = ly2 + y1\n",
    "\n",
    "                # Draw bounding box on original image\n",
    "                cv2.rectangle(img, (abs_x1, abs_y1), (abs_x2, abs_y2), (0, 255, 0), 2)\n",
    "\n",
    "                # Calculate size of the text\n",
    "                (font_w, font_h), baseline = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "\n",
    "                # Draw filled background rectangle for text\n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    (abs_x1, abs_y1 - font_h - 10),\n",
    "                    (abs_x1 + font_w + 6, abs_y1),\n",
    "                    (0, 255, 0),\n",
    "                    -1  # Filled rectangle\n",
    "                )\n",
    "\n",
    "                # Put the text on top of the background\n",
    "                cv2.putText(\n",
    "                    img,\n",
    "                    class_name,\n",
    "                    (abs_x1 + 3, abs_y1 - 4),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    (0, 0, 0),  # Black text for contrast\n",
    "                    2\n",
    "                )\n",
    "\n",
    "        ### Show result ###\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1ad9e-d669-48c0-9f79-b37ecf3ef5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define paths\n",
    "image_folder = 'D:/nada/grad_project/Car Plate Recognition - Final/datasets/plates/test/images'\n",
    "plate_model = YOLO('D:/nada/grad_project/Car Plate Recognition - Final/plates_best_so_far.pt')\n",
    "letter_model = YOLO('D:/nada/grad_project/Car Plate Recognition - Final/letters1.pt')\n",
    "\n",
    "# Confidence threshold\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(('.jpg', '.png')):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        ### STEP 1: Detect plates ###\n",
    "        plate_results = plate_model(img)\n",
    "        plate_boxes = plate_results[0].boxes.xyxy.tolist()\n",
    "        plate_confs = plate_results[0].boxes.conf.tolist()\n",
    "\n",
    "        for plate_box, plate_conf in zip(plate_boxes, plate_confs):\n",
    "            if plate_conf < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, plate_box)\n",
    "            cropped_plate = img[y1:y2, x1:x2]\n",
    "\n",
    "            ### STEP 2: Detect letters in the cropped plate ###\n",
    "            letter_results = letter_model(cropped_plate)\n",
    "            letter_boxes = letter_results[0].boxes.xyxy.tolist()\n",
    "            letter_classes = letter_results[0].boxes.cls.tolist()\n",
    "            letter_confs = letter_results[0].boxes.conf.tolist()\n",
    "            letter_names = letter_results[0].names\n",
    "\n",
    "            for box, cls, conf in zip(letter_boxes, letter_classes, letter_confs):\n",
    "                if conf < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                lx1, ly1, lx2, ly2 = map(int, box)\n",
    "                class_name = letter_names[int(cls)]\n",
    "\n",
    "                # Convert letter box back to original image coordinates\n",
    "                abs_x1 = lx1 + x1\n",
    "                abs_y1 = ly1 + y1\n",
    "                abs_x2 = lx2 + x1\n",
    "                abs_y2 = ly2 + y1\n",
    "\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(img, (abs_x1, abs_y1), (abs_x2, abs_y2), (0, 255, 0), 2)\n",
    "\n",
    "                # Get size of the label text\n",
    "                (font_w, font_h), _ = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "\n",
    "                # Calculate label position with padding\n",
    "                text_y = abs_y1 - 12\n",
    "                if text_y - font_h < 0:\n",
    "                    text_y = abs_y1 + font_h + 10\n",
    "\n",
    "                # Draw filled background rectangle\n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    (abs_x1, text_y - font_h - 6),\n",
    "                    (abs_x1 + font_w + 6, text_y),\n",
    "                    (0, 255, 0),\n",
    "                    -1\n",
    "                )\n",
    "\n",
    "                # Draw label text\n",
    "                cv2.putText(\n",
    "                    img,\n",
    "                    class_name,\n",
    "                    (abs_x1 + 3, text_y - 4),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    (0, 0, 0),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "        ### Show result ###\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7183f2-9a2b-46c1-bde8-a862c8a34cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Arabic label mapping\n",
    "arabic_labels = {\n",
    "    '0': '۰', '1': '۱', '2': '۲', '3': '۳', '4': '٤', '5': '٥', '6': '٦', '7': '٧', '8': '۸', '9': '۹',\n",
    "    '7aa': 'ح',\n",
    "    'Taa': 'ط',\n",
    "    'Thaa': 'ظ',\n",
    "    'ain': 'ع',\n",
    "    'alif': 'ا',\n",
    "    'baa': 'ب',\n",
    "    'daad': 'ض',\n",
    "    'daal': 'د',\n",
    "    'faa': 'ف',\n",
    "    'ghayn': 'غ',\n",
    "    'haa': 'ه',\n",
    "    'jeem': 'ج',\n",
    "    'kaaf': 'ك',\n",
    "    'khaa': 'خ',\n",
    "    'laam': 'ل',\n",
    "    'meem': 'م',\n",
    "    'noon': 'ن',\n",
    "    'qaaf': 'ق',\n",
    "    'raa': 'ر',\n",
    "    'saad': 'ص',\n",
    "    'seen': 'س',\n",
    "    'sheen': 'ش',\n",
    "    'taa': 'ت',\n",
    "    'thaa': 'ث',\n",
    "    'waw': 'و',\n",
    "    'yaa': 'ي',\n",
    "    'zaal': 'ذ',\n",
    "    'zay': 'ز'\n",
    "}\n",
    "\n",
    "# Helper to split Arabic letters (مقطعة)\n",
    "def split_arabic_letters(text):\n",
    "    return \"\\u200c\".join(text)  # Zero-width non-joiner between characters\n",
    "\n",
    "# Define paths\n",
    "image_folder = 'D:/nada/grad_project/Car Plate Recognition - Final/datasets/plates/test/images'\n",
    "plate_model = YOLO('D:/nada/grad_project/Car Plate Recognition - Final/plates_best_so_far.pt')\n",
    "letter_model = YOLO('D:/nada/grad_project/Car Plate Recognition - Final/letters1.pt')\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(('.jpg', '.png')):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Step 1: Detect plates\n",
    "        plate_results = plate_model(img)\n",
    "        plate_boxes = plate_results[0].boxes.xyxy.tolist()\n",
    "        plate_confs = plate_results[0].boxes.conf.tolist()\n",
    "\n",
    "        for plate_box, plate_conf in zip(plate_boxes, plate_confs):\n",
    "            if plate_conf < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, plate_box)\n",
    "            cropped_plate = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Draw bounding box for plate\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "\n",
    "            # Step 2: Detect letters in the cropped plate\n",
    "            letter_results = letter_model(cropped_plate)\n",
    "            letter_boxes = letter_results[0].boxes.xyxy.tolist()\n",
    "            letter_classes = letter_results[0].boxes.cls.tolist()\n",
    "            letter_confs = letter_results[0].boxes.conf.tolist()\n",
    "            letter_names = letter_results[0].names\n",
    "\n",
    "            # Collect letters sorted by x-coordinate\n",
    "            letters_info = []\n",
    "            for box, cls, conf in zip(letter_boxes, letter_classes, letter_confs):\n",
    "                if conf < confidence_threshold:\n",
    "                    continue\n",
    "                lx1, ly1, lx2, ly2 = map(int, box)\n",
    "                cx = (lx1 + lx2) / 2\n",
    "                class_name = letter_names[int(cls)]\n",
    "\n",
    "                # Draw letter bounding box (optional)\n",
    "                abs_x1 = lx1 + x1\n",
    "                abs_y1 = ly1 + y1\n",
    "                abs_x2 = lx2 + x1\n",
    "                abs_y2 = ly2 + y1\n",
    "                cv2.rectangle(img, (abs_x1, abs_y1), (abs_x2, abs_y2), (0, 255, 0), 2)\n",
    "\n",
    "                letters_info.append((cx, class_name))\n",
    "\n",
    "            # Sort and print the final plate characters\n",
    "            letters_info.sort(key=lambda x: x[0])\n",
    "            # Convert class names to Arabic characters\n",
    "            arabic_chars = [arabic_labels.get(name, name) for _, name in letters_info]\n",
    "            \n",
    "            # Separate letters and numbers\n",
    "            letters = [ch for ch in arabic_chars if not ch.isdigit()]\n",
    "            numbers = [ch for ch in arabic_chars if ch.isdigit()]\n",
    "            \n",
    "            # Reverse letters (Arabic RTL), keep numbers in original order\n",
    "            combined = letters[::-1] + numbers\n",
    "            \n",
    "            # Final string with isolated letters (مقطعة)\n",
    "            final_display_text = split_arabic_letters(combined)\n",
    "            \n",
    "            print(f\"{filename} → Plate: {final_display_text}\")\n",
    "\n",
    "            #print(f\"{filename} → Plate: {final_display_text}\")\n",
    "\n",
    "        # Show result\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f3003-c6bb-4a3d-a713-1ac84f2ed02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
